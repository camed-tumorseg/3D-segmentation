{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will be used for evaluation a trained model. TODO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/msc_student/vox2vox/config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: exchange config dictionary with config file and change corresponding lines in code to conf.<param>\n",
    "import config as conf\n",
    "import importlib\n",
    "importlib.reload(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install missing pre-requisites\n",
    "#!pip install tensorflow_addons\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from sys import stdout\n",
    "import concurrent.futures\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Numerical calculations\n",
    "import numpy as np\n",
    "\n",
    "# Own stuff\n",
    "from helper_functions import scan_loader\n",
    "from model.data_generator import DataGenerator\n",
    "from model import architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "### Sets up GPU(s).\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = conf.gpu\n",
    "\n",
    "# Tensorflow 2.XX\\n\",\n",
    "allow_multi_gpu = True\n",
    "tf_version = 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "if tf_version == 2 and allow_multi_gpu:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num test data: 125\n"
     ]
    }
   ],
   "source": [
    "### Finds all test data.\n",
    "\n",
    "# Fetches list of image paths for each modality and segmentation ground truth\n",
    "path_test = conf.dataset_mask_test\n",
    "t1_list    = sorted(glob.glob(path_test + '*t1.nii.gz'))\n",
    "t2_list    = sorted(glob.glob(path_test + '*t2.nii.gz'))\n",
    "t1ce_list  = sorted(glob.glob(path_test + '*t1ce.nii.gz'))\n",
    "flair_list = sorted(glob.glob(path_test + '*flair.nii.gz'))\n",
    "print(f\"Num test data: {len(t1_list)}\")\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(t1_list)):\n",
    "    test_data.append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates test data generator.\n",
    "\n",
    "# Test data generator\n",
    "test_gen = DataGenerator(test_data, \n",
    "                         shuffle      = False,\n",
    "                         batch_size   = conf.batch_size,\n",
    "                         input_dim    = conf.dataset_dim,\n",
    "                         output_dim   = conf.model_dim,\n",
    "                         n_channels   = conf.num_channels,\n",
    "                         n_classes    = conf.num_classes,\n",
    "                         ground_truth = False,\n",
    "                         preprocessed = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN: Vox2Vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Creates the model we want to evaluate on the test data.\n",
    "\n",
    "im_shape = (*conf.model_dim, conf.num_channels) \n",
    "gt_shape = (*conf.model_dim, conf.num_classes)\n",
    "class_weights = np.load('resources/class_weights.npy')\n",
    "\n",
    "# Initializes the model.\n",
    "gan = architecture.vox2vox(im_shape, gt_shape, class_weights,\n",
    "                           output_path = conf.output_path, \n",
    "                           save_images = conf.export_images)\n",
    "\n",
    "# Loads the model weights.\n",
    "gan.generator.load_weights(conf.weight_folder + '/Generator.h5')\n",
    "#gan.discriminator.load_weights(conf.output_path + '/backups/training_7_new_thresholds/Discriminator_62.h5')\n",
    "#gan.combined.load_weights(conf.output_path + '/backups/training_7_new_thresholds/Vox2Vox_62.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BraTS20_Validation_001\n",
      "Saved BraTS20_Validation_002\n",
      "Saved BraTS20_Validation_003\n",
      "Saved BraTS20_Validation_004\n",
      "Saved BraTS20_Validation_005\n",
      "Saved BraTS20_Validation_006\n",
      "Saved BraTS20_Validation_007\n",
      "Saved BraTS20_Validation_008\n",
      "Saved BraTS20_Validation_009\n",
      "Saved BraTS20_Validation_010\n",
      "Saved BraTS20_Validation_011\n",
      "Saved BraTS20_Validation_012\n",
      "Saved BraTS20_Validation_013\n",
      "Saved BraTS20_Validation_014\n",
      "Saved BraTS20_Validation_015\n",
      "Saved BraTS20_Validation_016\n",
      "Saved BraTS20_Validation_017\n",
      "Saved BraTS20_Validation_018\n",
      "Saved BraTS20_Validation_019\n",
      "Saved BraTS20_Validation_020\n",
      "Saved BraTS20_Validation_021\n",
      "Saved BraTS20_Validation_022\n",
      "Saved BraTS20_Validation_023\n",
      "Saved BraTS20_Validation_024\n",
      "Saved BraTS20_Validation_025\n",
      "Saved BraTS20_Validation_026\n",
      "Saved BraTS20_Validation_027\n",
      "Saved BraTS20_Validation_028\n",
      "Saved BraTS20_Validation_029\n",
      "Saved BraTS20_Validation_030\n",
      "Saved BraTS20_Validation_031\n",
      "Saved BraTS20_Validation_032\n",
      "Saved BraTS20_Validation_033\n",
      "Saved BraTS20_Validation_034\n",
      "Saved BraTS20_Validation_035\n",
      "Saved BraTS20_Validation_036\n",
      "Saved BraTS20_Validation_037\n",
      "Saved BraTS20_Validation_038\n",
      "Saved BraTS20_Validation_039\n",
      "Saved BraTS20_Validation_040\n",
      "Saved BraTS20_Validation_041\n",
      "Saved BraTS20_Validation_042\n",
      "Saved BraTS20_Validation_043\n",
      "Saved BraTS20_Validation_044\n",
      "Saved BraTS20_Validation_045\n",
      "Saved BraTS20_Validation_046\n",
      "Saved BraTS20_Validation_047\n",
      "Saved BraTS20_Validation_048\n",
      "Saved BraTS20_Validation_049\n",
      "Saved BraTS20_Validation_050\n",
      "Saved BraTS20_Validation_051\n",
      "Saved BraTS20_Validation_052\n",
      "Saved BraTS20_Validation_053\n",
      "Saved BraTS20_Validation_054\n",
      "Saved BraTS20_Validation_055\n",
      "Saved BraTS20_Validation_056\n",
      "Saved BraTS20_Validation_057\n",
      "Saved BraTS20_Validation_058\n",
      "Saved BraTS20_Validation_059\n",
      "Saved BraTS20_Validation_060\n",
      "Saved BraTS20_Validation_061\n",
      "Saved BraTS20_Validation_062\n",
      "Saved BraTS20_Validation_063\n",
      "Saved BraTS20_Validation_064\n",
      "Saved BraTS20_Validation_065\n",
      "Saved BraTS20_Validation_066\n",
      "Saved BraTS20_Validation_067\n",
      "Saved BraTS20_Validation_068\n",
      "Saved BraTS20_Validation_069\n",
      "Saved BraTS20_Validation_070\n",
      "Saved BraTS20_Validation_071\n",
      "Saved BraTS20_Validation_072\n",
      "Saved BraTS20_Validation_073\n",
      "Saved BraTS20_Validation_074\n",
      "Saved BraTS20_Validation_075\n",
      "Saved BraTS20_Validation_076\n",
      "Saved BraTS20_Validation_077\n",
      "Saved BraTS20_Validation_078\n",
      "Saved BraTS20_Validation_079\n",
      "Saved BraTS20_Validation_080\n",
      "Saved BraTS20_Validation_081\n",
      "Saved BraTS20_Validation_082\n",
      "Saved BraTS20_Validation_083\n",
      "Saved BraTS20_Validation_084\n",
      "Saved BraTS20_Validation_085\n",
      "Saved BraTS20_Validation_086\n",
      "Saved BraTS20_Validation_087\n",
      "Saved BraTS20_Validation_088\n",
      "Saved BraTS20_Validation_089\n",
      "Saved BraTS20_Validation_090\n",
      "Saved BraTS20_Validation_091\n",
      "Saved BraTS20_Validation_092\n",
      "Saved BraTS20_Validation_093\n",
      "Saved BraTS20_Validation_094\n",
      "Saved BraTS20_Validation_095\n",
      "Saved BraTS20_Validation_096\n",
      "Saved BraTS20_Validation_097\n",
      "Saved BraTS20_Validation_098\n",
      "Saved BraTS20_Validation_099\n",
      "Saved BraTS20_Validation_100\n",
      "Saved BraTS20_Validation_101\n",
      "Saved BraTS20_Validation_102\n",
      "Saved BraTS20_Validation_103\n",
      "Saved BraTS20_Validation_104\n",
      "Saved BraTS20_Validation_105\n",
      "Saved BraTS20_Validation_106\n",
      "Saved BraTS20_Validation_107\n",
      "Saved BraTS20_Validation_108\n",
      "Saved BraTS20_Validation_109\n",
      "Saved BraTS20_Validation_110\n",
      "Saved BraTS20_Validation_111\n",
      "Saved BraTS20_Validation_112\n",
      "Saved BraTS20_Validation_113\n",
      "Saved BraTS20_Validation_114\n",
      "Saved BraTS20_Validation_115\n",
      "Saved BraTS20_Validation_116\n",
      "Saved BraTS20_Validation_117\n",
      "Saved BraTS20_Validation_118\n",
      "Saved BraTS20_Validation_119\n",
      "Saved BraTS20_Validation_120\n",
      "Saved BraTS20_Validation_121\n",
      "Saved BraTS20_Validation_122\n",
      "Saved BraTS20_Validation_123\n",
      "Saved BraTS20_Validation_124\n",
      "Saved BraTS20_Validation_125\n"
     ]
    }
   ],
   "source": [
    "# Export test segmentation results\n",
    "\n",
    "# Use this section to upload your segmentation labels in .nii.gz format. \n",
    "# Note that each file should be named using the patient ID, given by the folder name \n",
    "# containing the 4 modalities for each patient. \n",
    "# In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., \n",
    "# the uploaded segmenations should be named ID.nii.gz\n",
    "\n",
    "batch_counter = 0\n",
    "for Xbatch, Ybatch, IDbatch in test_gen:\n",
    "    \n",
    "    # Predicts tumor segmentation for the batch\n",
    "    # gen_pred: num_batches x X x Y x Z x num_classes\n",
    "    gen_pred = gan.generator.predict(Xbatch)\n",
    "    \n",
    "    # Transforms segmentation back to original dimensions.\n",
    "    # The segmentation must have the same shape as the test data, or it can't be evaluated by BraTS!\n",
    "    _, gen_pred = scan_loader.make_size_batch(None, gen_pred, conf.dataset_dim)\n",
    "    \n",
    "    # Saves everry segmentation in this batch separately.\n",
    "    for i in range(len(IDbatch)):\n",
    "        data = gen_pred[i,:,:,:,:]\n",
    "        patient_id = IDbatch[i]\n",
    "        \n",
    "        # Finds the most likely class for every voxel.\n",
    "        seg = np.argmax(data, axis=-1).astype('float32')\n",
    "        \n",
    "        # Switches label 3 back to label 4 after applying a threshold to ET.\n",
    "        seg_enhancing = (seg == 3)\n",
    "        \n",
    "        if np.sum(seg_enhancing) < 1500:\n",
    "            seg[seg_enhancing] = 1\n",
    "        else:\n",
    "            seg[seg_enhancing] = 4\n",
    "        \n",
    "        # Applies a threshold to NT\n",
    "        seg_core = (seg == 1)\n",
    "        if np.sum(seg_core) < 500:\n",
    "            seg[seg_core] = 2\n",
    "        \n",
    "        \n",
    "        # Saves the segmentation to an output folder.\n",
    "        path = f\"{conf.output_path}/{conf.eval_export_path}/{patient_id}.nii.gz\"\n",
    "        scan_loader.save_img(seg, path)\n",
    "        print(f\"Saved {patient_id}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
