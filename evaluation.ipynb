{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will be used for evaluation a trained model. TODO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/msc_student/vox2vox/config.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: exchange config dictionary with config file and change corresponding lines in code to conf.<param>\n",
    "import config as conf\n",
    "import importlib\n",
    "importlib.reload(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install missing pre-requisites\n",
    "#!pip install tensorflow_addons\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from sys import stdout\n",
    "import concurrent.futures\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Numerical calculations\n",
    "import numpy as np\n",
    "\n",
    "# Own stuff\n",
    "import scan_loader\n",
    "from data_generator import DataGenerator\n",
    "import architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "### Sets up GPU(s).\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = conf.gpu\n",
    "\n",
    "# Tensorflow 2.XX\\n\",\n",
    "allow_multi_gpu = True\n",
    "tf_version = 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "if tf_version == 2 and allow_multi_gpu:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num test data: 125\n"
     ]
    }
   ],
   "source": [
    "### Finds all test data.\n",
    "\n",
    "# Fetches list of image paths for each modality and segmentation ground truth\n",
    "path_test = conf.dataset_mask_test\n",
    "t1_list    = sorted(glob.glob(path_test + '*t1.nii.gz'))\n",
    "t2_list    = sorted(glob.glob(path_test + '*t2.nii.gz'))\n",
    "t1ce_list  = sorted(glob.glob(path_test + '*t1ce.nii.gz'))\n",
    "flair_list = sorted(glob.glob(path_test + '*flair.nii.gz'))\n",
    "seg_list   = sorted(glob.glob(path_test + '*seg.nii.gz'))\n",
    "print(f\"Num test data: {len(t1_list)}\")\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(t1_list)):\n",
    "    test_data.append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates test data generator.\n",
    "\n",
    "# Test data generator\n",
    "test_gen = DataGenerator(test_data, \n",
    "                         shuffle      = False,\n",
    "                         batch_size   = conf.batch_size,\n",
    "                         input_dim    = conf.dataset_dim,\n",
    "                         output_dim   = conf.model_dim,\n",
    "                         n_channels   = conf.num_channels,\n",
    "                         n_classes    = conf.num_classes,\n",
    "                         ground_truth = False,\n",
    "                         preprocessed = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN: Vox2Vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Creates the model we want to evaluate on the test data.\n",
    "\n",
    "im_shape = (*conf.model_dim, conf.num_channels) \n",
    "gt_shape = (*conf.model_dim, conf.num_classes)\n",
    "class_weights = np.load('class_weights.npy')\n",
    "\n",
    "# Initializes the model.\n",
    "gan = architecture.vox2vox(im_shape, gt_shape, class_weights,\n",
    "                           output_path = conf.output_path, \n",
    "                           save_images = conf.export_images)\n",
    "\n",
    "# Loads the model weights.\n",
    "gan.generator.load_weights(conf.output_path + '/backups/training_7_new_thresholds/Generator_62.h5')\n",
    "gan.discriminator.load_weights(conf.output_path + '/backups/training_7_new_thresholds/Discriminator_62.h5')\n",
    "gan.combined.load_weights(conf.output_path + '/backups/training_7_new_thresholds/Vox2Vox_62.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BraTS20_Validation_001\n",
      "Saved BraTS20_Validation_002\n",
      "Saved BraTS20_Validation_003\n",
      "Saved BraTS20_Validation_004\n",
      "Saved BraTS20_Validation_005\n",
      "Saved BraTS20_Validation_006\n",
      "Saved BraTS20_Validation_007\n",
      "Saved BraTS20_Validation_008\n",
      "Saved BraTS20_Validation_009\n",
      "Saved BraTS20_Validation_010\n",
      "Saved BraTS20_Validation_011\n",
      "Saved BraTS20_Validation_012\n",
      "Saved BraTS20_Validation_013\n",
      "Saved BraTS20_Validation_014\n",
      "Saved BraTS20_Validation_015\n",
      "Saved BraTS20_Validation_016\n",
      "Saved BraTS20_Validation_017\n",
      "Saved BraTS20_Validation_018\n",
      "Saved BraTS20_Validation_019\n",
      "Saved BraTS20_Validation_020\n",
      "Saved BraTS20_Validation_021\n",
      "Saved BraTS20_Validation_022\n",
      "Saved BraTS20_Validation_023\n",
      "Saved BraTS20_Validation_024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-22dac6cf1007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatch_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mXbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIDbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Predicts tumor segmentation for the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vox2vox/lib/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vox2vox/lib/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vox2vox/data_generator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# Loads the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Optional: Crops the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vox2vox/data_generator.py\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Loads data. Only normalizes if data is not preprocessed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIDs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             X[i], y[i], patient_ids[i] = scan_loader.load_img(IDs, ground_truth = self.ground_truth, \n\u001b[0m\u001b[1;32m    135\u001b[0m                                                               normalize=not self.preprocessed)            \n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vox2vox/scan_loader.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(img_files, ground_truth, normalize)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Saves the normalized modality as a channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mX_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Also crops the MRT-image to 160x192x128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Export test segmentation results\n",
    "\n",
    "# Use this section to upload your segmentation labels in .nii.gz format. \n",
    "# Note that each file should be named using the patient ID, given by the folder name \n",
    "# containing the 4 modalities for each patient. \n",
    "# In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., \n",
    "# the uploaded segmenations should be named ID.nii.gz\n",
    "\n",
    "batch_counter = 0\n",
    "for Xbatch, Ybatch, IDbatch in test_gen:\n",
    "    \n",
    "    # Predicts tumor segmentation for the batch\n",
    "    # gen_pred: num_batches x X x Y x Z x num_classes\n",
    "    gen_pred = gan.generator.predict(Xbatch)\n",
    "    \n",
    "    # Transforms segmentation back to original dimensions.\n",
    "    # The segmentation must have the same shape as the test data, or it can't be evaluated by BraTS!\n",
    "    _, gen_pred = scan_loader.make_size_batch(None, gen_pred, conf.dataset_dim)\n",
    "    \n",
    "    # Saves everry segmentation in this batch separately.\n",
    "    for i in range(len(IDbatch)):\n",
    "        data = gen_pred[i,:,:,:,:]\n",
    "        patient_id = IDbatch[i]\n",
    "        \n",
    "        # Finds the most likely class for every voxel.\n",
    "        seg = np.argmax(data, axis=-1).astype('float32')\n",
    "        \n",
    "        # Switches label 3 back to label 4 after applying a threshold to ET.\n",
    "        seg_enhancing = (seg == 3)\n",
    "        \n",
    "        if np.sum(seg_enhancing) < 1500:\n",
    "            seg[seg_enhancing] = 1\n",
    "        else:\n",
    "            seg[seg_enhancing] = 4\n",
    "        \n",
    "        # Applies a threshold to NT\n",
    "        seg_core = (seg == 1)\n",
    "        if np.sum(seg_core) < 500:\n",
    "            seg[seg_core] = 2\n",
    "        \n",
    "        \n",
    "        # Saves the segmentation to an output folder.\n",
    "        path = f\"{conf.output_path}/{conf.eval_export_path}/{patient_id}_seg.nii.gz\"\n",
    "        scan_loader.save_img(seg, path)\n",
    "        print(f\"Saved {patient_id}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
